[project]
name = "atomiclm"
version = "0.1.0"
description = "From-scratch implementation of a decoder-only transformer language model in Python/PyTorch"
readme = "README.md"
license = "MIT"
requires-python = ">=3.12"
authors = [
    { name = "Flavio Mutti" },
]
keywords = ["llm", "transformer", "bpe", "tokenizer", "pytorch", "from-scratch"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Education",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
dependencies = [
    "regex>=2025.11.3",
    "torch>=2.6.0; sys_platform == 'linux' or (sys_platform == 'darwin' and platform_machine == 'arm64')",
    "torch==2.8.0; sys_platform == 'darwin' and platform_machine == 'x86_64'",
]

[project.optional-dependencies]
tiktoken = [
    "tiktoken>=0.12.0",
]

[tool.uv]
environments = [
    "sys_platform == 'linux'",
    "sys_platform == 'darwin' and platform_machine == 'arm64'",
    "sys_platform == 'darwin' and platform_machine == 'x86_64'",
]

[build-system]
requires = ["uv_build>=0.9.21,<0.10.0"]
build-backend = "uv_build"

[dependency-groups]
dev = [
    "pytest>=9.0.2",
    "numpy<2; sys_platform == 'darwin' and platform_machine == 'x86_64'",
    "numpy; sys_platform == 'linux' or (sys_platform == 'darwin' and platform_machine == 'arm64')",
]
